{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-21T17:36:03.442835Z","iopub.execute_input":"2022-08-21T17:36:03.443228Z","iopub.status.idle":"2022-08-21T17:36:03.460697Z","shell.execute_reply.started":"2022-08-21T17:36:03.443194Z","shell.execute_reply":"2022-08-21T17:36:03.459487Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"> # Importing Libraries","metadata":{}},{"cell_type":"markdown","source":"Here we are importing all the important libraries to solve the sherlock text. In this we will create lstm model and that will predict the next word. For doing this we have taken pandas numpy matplot for data visualization & reading, creating dataframe many more.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n# Nltk specific requirement\nimport nltk\nnltk.download('omw-1.4')\nimport re #REGEX very important for text processing\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom numpy import unique\n# LSTM, and all \nfrom keras.layers import Dense,Dropout, RNN, LSTM, Activation, Embedding\nfrom keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:04.257048Z","iopub.execute_input":"2022-08-21T17:36:04.257580Z","iopub.status.idle":"2022-08-21T17:36:04.458130Z","shell.execute_reply.started":"2022-08-21T17:36:04.257546Z","shell.execute_reply":"2022-08-21T17:36:04.457109Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"> # Read Text\n**To read this data we will open that file from folder. After that we will be able to read sherlock text**","metadata":{}},{"cell_type":"code","source":"# df = open(\"../input/sherlocktxt/sherlock.txt\")\n# df.read()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:05.524716Z","iopub.execute_input":"2022-08-21T17:36:05.525062Z","iopub.status.idle":"2022-08-21T17:36:05.529572Z","shell.execute_reply.started":"2022-08-21T17:36:05.525033Z","shell.execute_reply":"2022-08-21T17:36:05.528653Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"df = open(\"../input/sherlocktxt/sherlock.txt\")\ntext = df.read()    \nprint(text[700:1483])","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:06.216859Z","iopub.execute_input":"2022-08-21T17:36:06.218401Z","iopub.status.idle":"2022-08-21T17:36:06.228112Z","shell.execute_reply.started":"2022-08-21T17:36:06.218353Z","shell.execute_reply":"2022-08-21T17:36:06.227008Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"def sequence_to_sum(seq):\n    \"\"\"\n    Params: Seq\n    return: seq_ac\n    desc: This function shows the sum of vowel sequence. \n    \"\"\"\n    seq_ac = []\n    xn = 0\n    mean = np.mean(seq)\n    \n    for xi in seq:\n        xn = xi + xn - mean\n        seq_ac.append(xn)\n    seq_ac = np.array(seq_ac)\n    return seq_ac","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:07.191198Z","iopub.execute_input":"2022-08-21T17:36:07.191564Z","iopub.status.idle":"2022-08-21T17:36:07.197664Z","shell.execute_reply.started":"2022-08-21T17:36:07.191534Z","shell.execute_reply":"2022-08-21T17:36:07.196499Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"def vowel_to_sequence(c1, c2, text):\n    \"\"\"\n    Params: c1, c2, text\n    return: sequence\n    We made this function to convert the vowels into sequence. \n    \"\"\"\n    sequence = []\n    \n    for i in text:\n        if i == c1 or i == c1.upper():\n            sequence.append(-1)\n        elif i == c2 or i == c2.upper():\n            sequence.append(1)\n        else:\n            pass\n    return sequence","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:08.255047Z","iopub.execute_input":"2022-08-21T17:36:08.256070Z","iopub.status.idle":"2022-08-21T17:36:08.262929Z","shell.execute_reply.started":"2022-08-21T17:36:08.256024Z","shell.execute_reply":"2022-08-21T17:36:08.261398Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"seq = vowel_to_sequence('o', 'u', text)\nseq[0:10]","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:08.733717Z","iopub.execute_input":"2022-08-21T17:36:08.734067Z","iopub.status.idle":"2022-08-21T17:36:08.899178Z","shell.execute_reply.started":"2022-08-21T17:36:08.734037Z","shell.execute_reply":"2022-08-21T17:36:08.898168Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"seq_ac = sequence_to_sum(seq)\nseq_ac","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:10.416649Z","iopub.execute_input":"2022-08-21T17:36:10.417576Z","iopub.status.idle":"2022-08-21T17:36:10.446157Z","shell.execute_reply.started":"2022-08-21T17:36:10.417530Z","shell.execute_reply":"2022-08-21T17:36:10.445202Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"> # Data Visualization","metadata":{}},{"cell_type":"markdown","source":"This is the data visualization part for vowels seq. Here we have seen how sequenced are those vowels. It helps us to get an idea of the further process.","metadata":{}},{"cell_type":"code","source":"plt.style.use('seaborn-poster')\nplt.figure(figsize = (10,8))\nplt.xlabel(\"Elements\")\nplt.ylabel(\"Cumulative Sum\")\nplt.plot(seq_ac[0:1500])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:10.685155Z","iopub.execute_input":"2022-08-21T17:36:10.685993Z","iopub.status.idle":"2022-08-21T17:36:10.893890Z","shell.execute_reply.started":"2022-08-21T17:36:10.685949Z","shell.execute_reply":"2022-08-21T17:36:10.892972Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"> # Text Preprocessing","metadata":{}},{"cell_type":"markdown","source":"It is very imp part of the text analysis. That convert our data into the processed data. We generally not use the whole word for prediction. We have to apply lemmatize and stemmer and split to see the particular word. Those words we will use for next step. The turning point of the data.","metadata":{}},{"cell_type":"code","source":"\nps = PorterStemmer()\nlm = WordNetLemmatizer()\n\ndef word_text_preProcess(text, limit):\n    \"\"\"\\\n    Params: text , limit\n    return: processed data\n    desc: This function will take the raw data \n          and convert that into capital \n          and take that into the base root.\n    \"\"\"\n    word_text = []\n    for i in text[0:limit].split(\" \"):\n        upper = i.upper()\n        special_char = re.sub(\"[^A-ZS0-9]\", \"\", upper)\n        stemmed_txt = ps.stem(special_char)\n        lemmed_txt = lm.lemmatize(stemmed_txt)\n        word_text.append(lemmed_txt.upper())\n\n    return word_text","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:11.038123Z","iopub.execute_input":"2022-08-21T17:36:11.038669Z","iopub.status.idle":"2022-08-21T17:36:11.044953Z","shell.execute_reply.started":"2022-08-21T17:36:11.038638Z","shell.execute_reply":"2022-08-21T17:36:11.044000Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# text\n\nlimit = 10000\nword_text = word_text_preProcess(text, limit)\n# len(word_text)\ndef lag_of_words(word_text):\n    \"\"\"\n    Params: word_text\n    return: str_X, str_Y\n    desc: It will take the processed text for creating an X and y in string format.\n          There we are taking only 3 lags at one go and predicting only one word.\n    \"\"\"\n    str_X = []\n    str_Y = []\n    for i in range(3,len(word_text),1):\n        first_word = word_text[i - 3]\n        second_word = word_text[i - 2]\n        third_word = word_text[i - 1]\n        fourth_word = word_text[i]\n        Str_x = str(first_word) + \" \" + str(second_word) + \" \" + str (third_word)\n        Str_y = str(fourth_word)\n        str_X.append(Str_x)\n        str_Y.append(Str_y)\n    return str_X, str_Y\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:11.479132Z","iopub.execute_input":"2022-08-21T17:36:11.480390Z","iopub.status.idle":"2022-08-21T17:36:11.530692Z","shell.execute_reply.started":"2022-08-21T17:36:11.480336Z","shell.execute_reply":"2022-08-21T17:36:11.529822Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"str_X, str_Y = lag_of_words(word_text)\n\ndef show_data_XandY(str_X, str_Y, rows):\n    \"\"\"\n    Params: str_X, str_Y, rows\n    return: dataframe\n    desc: That function shows the data which is going to predict that will matching fine or not.\n          You can do coparision through this DF.\n    \"\"\"\n    Q = pd.DataFrame([str_X, str_Y]).T\n    Q. columns = ['Xdata', \"Ypred\"]\n    return Q.head(rows)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:37:24.411756Z","iopub.execute_input":"2022-08-21T17:37:24.412127Z","iopub.status.idle":"2022-08-21T17:37:24.420018Z","shell.execute_reply.started":"2022-08-21T17:37:24.412076Z","shell.execute_reply":"2022-08-21T17:37:24.418838Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"> # DataFrame Contains X and Y","metadata":{}},{"cell_type":"markdown","source":"Here you will see DataFrame of X and Y. This will help us to compare our end prediction. To get the end prediction it will show the first three words in X data and fourth is predicted word contains Ypredcol.","metadata":{}},{"cell_type":"code","source":"show_data_XandY(str_X, str_Y, 20)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:37:27.335964Z","iopub.execute_input":"2022-08-21T17:37:27.336642Z","iopub.status.idle":"2022-08-21T17:37:27.398073Z","shell.execute_reply.started":"2022-08-21T17:37:27.336602Z","shell.execute_reply":"2022-08-21T17:37:27.397118Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"\n## We are looking for unique words of text. That text will help you to decide your input shape.\n","metadata":{}},{"cell_type":"code","source":"unique_words = unique(word_text)\nlen(unique_words)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:36:30.042542Z","iopub.execute_input":"2022-08-21T17:36:30.042895Z","iopub.status.idle":"2022-08-21T17:36:30.051308Z","shell.execute_reply.started":"2022-08-21T17:36:30.042865Z","shell.execute_reply":"2022-08-21T17:36:30.050252Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"len(str_X)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:05.845115Z","iopub.execute_input":"2022-08-21T17:38:05.845496Z","iopub.status.idle":"2022-08-21T17:38:05.852328Z","shell.execute_reply.started":"2022-08-21T17:38:05.845465Z","shell.execute_reply":"2022-08-21T17:38:05.851298Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"> # Text to int or bool form","metadata":{}},{"cell_type":"markdown","source":"Now in this step our data will convert into an array or bool. For example where your desired word is present there it will show true or 1 and in rest of the places will be false or 0.","metadata":{}},{"cell_type":"code","source":"X_arr = np.zeros((len(str_X), len(word_text), 3))\n# X_arr = np.zeros((len(str_X), len(word_text), 3), dtypes = bool)\nY_arr = np.zeros((len(str_X), len(word_text)))\n# Y_arr = np.zeros((len(str_X), len(word_text)), dtypes = bool)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:07.040040Z","iopub.execute_input":"2022-08-21T17:38:07.040428Z","iopub.status.idle":"2022-08-21T17:38:07.048337Z","shell.execute_reply.started":"2022-08-21T17:38:07.040396Z","shell.execute_reply":"2022-08-21T17:38:07.047336Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"def positionOfWordFinder(unique_words,X_arr):\n    \"\"\"\n    Params: unique_words, X_arr\n    return: word position\n    desc: There you will see when you want to know about the \n          position of the word in lakhs of text you can use \n          this function.\n    \"\"\"\n    word_pos_finder = {}\n    for i in range(0, len(unique_words), 1):\n        word_pos_finder[unique_words[i]] = i\n    for i, j in enumerate(str_X):\n    #     if i == 5:\n    #         print(\"index\", i,'line', j)\n    #         print(\"index\", i,'line', j.split(\" \"))\n    #         print(\"index\", i,'line', list(enumerate(j.split(\" \"))))\n    #         break\n        for j, k in enumerate(j.split(\" \")):\n    #         if i == 5:\n    #             print(i, j, k)\n    #             break\n            pos = word_pos_finder[k]\n            X_arr[i,pos, j]=  1\n    \n    return word_pos_finder\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:08.182194Z","iopub.execute_input":"2022-08-21T17:38:08.182863Z","iopub.status.idle":"2022-08-21T17:38:08.189128Z","shell.execute_reply.started":"2022-08-21T17:38:08.182822Z","shell.execute_reply":"2022-08-21T17:38:08.188157Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"word_pos_finder = positionOfWordFinder(unique_words, X_arr)\n\nword_pos_finder['GUTENBERG']","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:08.766952Z","iopub.execute_input":"2022-08-21T17:38:08.768073Z","iopub.status.idle":"2022-08-21T17:38:08.789960Z","shell.execute_reply.started":"2022-08-21T17:38:08.768021Z","shell.execute_reply":"2022-08-21T17:38:08.788975Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# X_arr","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:09.794934Z","iopub.execute_input":"2022-08-21T17:38:09.795780Z","iopub.status.idle":"2022-08-21T17:38:09.800475Z","shell.execute_reply.started":"2022-08-21T17:38:09.795742Z","shell.execute_reply":"2022-08-21T17:38:09.799273Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"markdown","source":"> # Processing TExt of Y","metadata":{}},{"cell_type":"code","source":"for i, j in enumerate(str_Y):\n    pos = word_pos_finder[j]\n    Y_arr[i, pos] = 1","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:59:08.119325Z","iopub.execute_input":"2022-08-21T17:59:08.119999Z","iopub.status.idle":"2022-08-21T17:59:08.126290Z","shell.execute_reply.started":"2022-08-21T17:59:08.119963Z","shell.execute_reply":"2022-08-21T17:59:08.125187Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"Y_arr","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:11.762511Z","iopub.execute_input":"2022-08-21T17:38:11.762874Z","iopub.status.idle":"2022-08-21T17:38:11.772454Z","shell.execute_reply.started":"2022-08-21T17:38:11.762844Z","shell.execute_reply":"2022-08-21T17:38:11.771213Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"len(word_text)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:12.567893Z","iopub.execute_input":"2022-08-21T17:38:12.568257Z","iopub.status.idle":"2022-08-21T17:38:12.576695Z","shell.execute_reply.started":"2022-08-21T17:38:12.568225Z","shell.execute_reply":"2022-08-21T17:38:12.574840Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"len(unique_words)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:13.333215Z","iopub.execute_input":"2022-08-21T17:38:13.333896Z","iopub.status.idle":"2022-08-21T17:38:13.341386Z","shell.execute_reply.started":"2022-08-21T17:38:13.333855Z","shell.execute_reply":"2022-08-21T17:38:13.340074Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":"> # LSTM Model ","metadata":{}},{"cell_type":"markdown","source":"Using the lstm model and also have used the embedding but didnt not get very much difference. So if it works for you. You definitely can add. ","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n# model.add(Embedding(len(word_text), 50, input_length=50))\n\n# nn.add(LSTM(100, return_sequences = True, input_shape =(len(word_text), len(unique_words))))\nmodel.add(LSTM(100, return_sequences = True, input_shape = (len(unique_words), 3)))\nmodel.add(LSTM(100))\n# model.add(LSTM(300))\nmodel.add(Dropout(0.15))\nmodel.add(Dense(len(unique_words)))\nmodel.add(Dense(len(unique_words)))\nmodel.add(Activation('relu'))\nmodel.add(Dense(len(word_text), activation = \"softmax\"))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:13.941506Z","iopub.execute_input":"2022-08-21T17:38:13.942411Z","iopub.status.idle":"2022-08-21T17:38:14.345137Z","shell.execute_reply.started":"2022-08-21T17:38:13.942362Z","shell.execute_reply":"2022-08-21T17:38:14.344018Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:14.563272Z","iopub.execute_input":"2022-08-21T17:38:14.563627Z","iopub.status.idle":"2022-08-21T17:38:14.573510Z","shell.execute_reply.started":"2022-08-21T17:38:14.563598Z","shell.execute_reply":"2022-08-21T17:38:14.571863Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\nmodel.fit(X_arr, Y_arr, batch_size=100, epochs = 15)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:38:15.151204Z","iopub.execute_input":"2022-08-21T17:38:15.152166Z","iopub.status.idle":"2022-08-21T17:39:39.496807Z","shell.execute_reply.started":"2022-08-21T17:38:15.152119Z","shell.execute_reply":"2022-08-21T17:39:39.495741Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":"> # Prediction","metadata":{}},{"cell_type":"markdown","source":"It takes the 3 word bcz we have defined that into the lag function. So here y prediction will be after 3 word.","metadata":{}},{"cell_type":"code","source":"input_X_arr = np.zeros((1,len(unique_words),3), dtype = int)\nsent = input(\"Enter a a sentence of [3 words]\")\n\nsent = sent.upper()\ntry: \n    for i,j in enumerate(sent.split(\" \")):\n        pos = word_pos_finder[j]\n        input_X_arr[i, pos, j] = 1\nexcept IndexError:\n    print(\"IndexError But that value had been saved in input array\", )\nR = pd.DataFrame([unique_words, model.predict([input_X_arr])[0]]).T\nR.columns = [\"Word\", \"Pred\"]\nR.sort_values(by= \"Pred\", ascending = False).head(1)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T17:39:39.498819Z","iopub.execute_input":"2022-08-21T17:39:39.500356Z","iopub.status.idle":"2022-08-21T17:40:05.157949Z","shell.execute_reply.started":"2022-08-21T17:39:39.500316Z","shell.execute_reply":"2022-08-21T17:40:05.157036Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}